{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxeyelGk_Tp4"
      },
      "source": [
        "# Classifying Handwritten digits using Tensorflow 2.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbg_FbbPU2fe"
      },
      "source": [
        "\n",
        "The **[MNIST Handwritten Digit Classification Dataset](http://yann.lecun.com/exdb/mnist/)** consists of 60,000 training images and 10,000 testing images of handwritten digits.\n",
        "\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
        "\n",
        "![alt text](https://i.imgur.com/Su00XUA.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJx67lrIomOJ",
        "outputId": "d5e9e628-361b-4f85-fa21-706ff301226c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "NJE-FICUCucn"
      },
      "outputs": [],
      "source": [
        "# Loading the Handwritten MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo4I0gVDC7R7",
        "outputId": "7ac5d4e4-8292-4794-82cc-957234ce02e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiMJW_pSDZpe"
      },
      "source": [
        "From above we can observe that there are 60K training samples and each sample is of size (28,28) and 10K testing samples with same size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "82z5p5pEDOyD",
        "outputId": "582abd3f-fb23-4006-fefc-933202eac15d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample = x_train[500,:,:]\n",
        "plt.imshow(sample)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WHnLV1WD5aA",
        "outputId": "1a30c952-59db-4373-9f99-b4adfc759b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min value:  0\n",
            "Max value:  255\n"
          ]
        }
      ],
      "source": [
        "print(\"Min value: \", sample.min())\n",
        "print(\"Max value: \", sample.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZDo255VEFh0"
      },
      "source": [
        "From the above we can confirm that the each image in the dataset is in the range [0-255]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "hFn9yQOwEEbK"
      },
      "outputs": [],
      "source": [
        "# Normalize the dataset between [0, 1] for the model to converge faster\n",
        "x_train = x_train / x_train.max()\n",
        "x_test = x_test / x_test.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "I6UrGeB6FP7v",
        "outputId": "19412937-4c45-4797-829c-1146e47d4db1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min value:  0.0\n",
            "Max value:  1.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample = x_train[500,:,:]\n",
        "\n",
        "print(\"Min value: \", sample.min())\n",
        "print(\"Max value: \", sample.max())\n",
        "\n",
        "plt.imshow(sample)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbPvxAbUFbl_"
      },
      "source": [
        "After normalising the data, we obseve that there is no loss in data and is normalised between [0, 1] range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "9_QMQ0skHUfe"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape((-1, 28 * 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "JdO2r55THd9B"
      },
      "outputs": [],
      "source": [
        "x_test = x_test.reshape((-1, 28 * 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "t0ZQe1yjHK-o"
      },
      "outputs": [],
      "source": [
        "# One-hot representation of the labels.\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10) \n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "WDLy5L82QRbQ"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "rJp716kcGNb-"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MbFWsIvFl-t",
        "outputId": "c4d83912-bec8-4cad-eaf8-dab0ac0049a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden_layer_1 (Dense)       (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "hidden_layer_2 (Dense)       (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 937,482\n",
            "Trainable params: 937,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=512, activation='sigmoid', \n",
        "                input_shape=(28 * 28, ), name=\"hidden_layer_1\"))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units=1024, activation='sigmoid', \n",
        "                name=\"hidden_layer_2\"))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10, name='output_layer', activation = 'softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "rKiKZt3sIhVL"
      },
      "outputs": [],
      "source": [
        "# Compiling the model with Adam optimizer and categorical cross entropy loss\n",
        "# Also we are keeping a track of the accuracy of the model at each epoch\n",
        "model.compile(optimizer='Adam', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy4kjwzuJRG8",
        "outputId": "780bee84-242a-4c68-b829-18ba28a0e968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0520 - accuracy: 0.6645 - val_loss: 0.2626 - val_accuracy: 0.9235\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2881 - accuracy: 0.9123 - val_loss: 0.2214 - val_accuracy: 0.9334\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2180 - accuracy: 0.9337 - val_loss: 0.1678 - val_accuracy: 0.9509\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1619 - accuracy: 0.9517 - val_loss: 0.1363 - val_accuracy: 0.9592\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1337 - accuracy: 0.9589 - val_loss: 0.1222 - val_accuracy: 0.9638\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1084 - accuracy: 0.9663 - val_loss: 0.1032 - val_accuracy: 0.9703\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0914 - accuracy: 0.9730 - val_loss: 0.0986 - val_accuracy: 0.9712\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0780 - accuracy: 0.9760 - val_loss: 0.0954 - val_accuracy: 0.9724\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0678 - accuracy: 0.9792 - val_loss: 0.0933 - val_accuracy: 0.9714\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9813 - val_loss: 0.0863 - val_accuracy: 0.9747\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.9833 - val_loss: 0.0891 - val_accuracy: 0.9740\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.0807 - val_accuracy: 0.9774\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.0795 - val_accuracy: 0.9780\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.0736 - val_accuracy: 0.9789\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9900 - val_loss: 0.0785 - val_accuracy: 0.9796\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9899 - val_loss: 0.0800 - val_accuracy: 0.9783\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 0.0947 - val_accuracy: 0.9758\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.0823 - val_accuracy: 0.9788\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 0.0846 - val_accuracy: 0.9791\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.0819 - val_accuracy: 0.9796\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.0826 - val_accuracy: 0.9803\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0882 - val_accuracy: 0.9796\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 0.0925 - val_accuracy: 0.9785\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0897 - val_accuracy: 0.9815\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.0851 - val_accuracy: 0.9817\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0121 - accuracy: 0.9955 - val_loss: 0.0888 - val_accuracy: 0.9803\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0897 - val_accuracy: 0.9803\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0102 - accuracy: 0.9961 - val_loss: 0.0950 - val_accuracy: 0.9808\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0999 - val_accuracy: 0.9805\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.1001 - val_accuracy: 0.9803\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 0.0928 - val_accuracy: 0.9812\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0943 - val_accuracy: 0.9815\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.1021 - val_accuracy: 0.9808\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0992 - val_accuracy: 0.9814\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1045 - val_accuracy: 0.9811\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.1105 - val_accuracy: 0.9801\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0978 - val_accuracy: 0.9808\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.1003 - val_accuracy: 0.9818\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.1094 - val_accuracy: 0.9806\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0999 - val_accuracy: 0.9824\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1121 - val_accuracy: 0.9802\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1128 - val_accuracy: 0.9796\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.1021 - val_accuracy: 0.9819\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.1114 - val_accuracy: 0.9816\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.1156 - val_accuracy: 0.9794\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.1039 - val_accuracy: 0.9832\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.1093 - val_accuracy: 0.9822\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1011 - val_accuracy: 0.9827\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1049 - val_accuracy: 0.9827\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.1120 - val_accuracy: 0.9819\n"
          ]
        }
      ],
      "source": [
        "# Training the model. \n",
        "training = model.fit(x_train, y_train, batch_size=128, epochs=50, validation_split=0.2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyzDJ6o0J_24",
        "outputId": "918fb81f-10f1-40c8-b050-e22066346059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1013 - accuracy: 0.9833\n",
            "Test accuracy: 0.983299970626831\n"
          ]
        }
      ],
      "source": [
        "# evaluate the model (trained with sigmoid activation at the hidden layer)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iRcs5NyKDwP"
      },
      "source": [
        "From the above model architecture we got 98.32% accuracy on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK5elS8-KqCj",
        "outputId": "130358e6-38b8-4bec-9fcd-0e08a9d80ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1124 - accuracy: 0.9835\n",
            "Test accuracy: 0.9835000038146973\n"
          ]
        }
      ],
      "source": [
        "# evaluate the model (trained with relu activation at the hidden layer)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm7cMsF2Kt5l"
      },
      "source": [
        "Using relu activation at the hidden layers, we got 98.35 % accuracy on the test dataset"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "JL8GMQz2R90b",
        "HruLQ2fqS3f2",
        "PwEj36wcbsXF"
      ],
      "name": "Assignment_1_Question_2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
